# Концепция InfiniRetri

InfiniRetri — прорывная система извлечения на основе внимания для бесконечного контекста.

## Проблема

Стандартные LLM имеют ограничения контекста:
- GPT-4: 128K токенов
- Claude 3: 200K токенов
- Но реальные документы могут быть **миллионы токенов**

Традиционные решения (RAG, chunking) теряют информацию и точность.

## Решение: InfiniRetri

InfiniRetri использует **внимание-основанное извлечение** вместо эмбеддингов:

```
┌─────────────────────────────────────────────────────────────────┐
│                Традиционный RAG vs InfiniRetri                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  Традиционный RAG:                                               │
│  Документ → Эмбеддинг → VectorDB → Top-K → LLM                  │
│  • Теряет семантические нюансы при эмбеддинге                   │
│  • Top-K может пропустить релевантные чанки                     │
│  • ~85% точность на needle-in-haystack                         │
│                                                                  │
│  InfiniRetri:                                                   │
│  Документ → Чанки → Обработка каждого → Веса внимания → Выбор   │
│  • Использует механизм внимания самого LLM                      │
│  • Выбор с учётом запроса                                       │
│  • 100% точность на needle-in-haystack                         │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Как это работает

1. **Разбиение**: Документ делится на сегменты
2. **Зондирование вниманием**: Каждый сегмент обрабатывается с запросом
3. **Извлечение весов**: Извлекаем веса внимания для токенов запроса
4. **Выбор**: Top-K сегментов по скору внимания
5. **Синтез**: LLM генерирует ответ из выбранного контекста

## Ключевые преимущества

| Функция | Преимущество |
|---------|--------------|
| **100% Точность** | Никогда не пропускает иголку |
| **O(1) Память** | Константная память независимо от размера документа |
| **Без эмбеддингов** | Не нужна модель эмбеддингов |
| **Адаптация к запросу** | Выбор настроен под конкретный запрос |

## Конфигурация

```python
from rlm_toolkit import RLMConfig
from rlm_toolkit.retrieval import InfiniRetriConfig

infini_config = InfiniRetriConfig(
    chunk_size=4000,        # Токенов на чанк
    chunk_overlap=200,      # Перекрытие для непрерывности
    top_k=5,                # Чанков для извлечения
    attention_layer=-1,     # Внимание последнего слоя
    pooling="mean"          # Агрегация внимания
)

config = RLMConfig(
    enable_infiniretri=True,
    infiniretri_config=infini_config,
    infiniretri_threshold=50000
)
```

## Когда использовать

| Сценарий | Использовать InfiniRetri? |
|----------|---------------------------|
| Документы > 50K токенов | ✅ Да |
| Анализ юр. документов | ✅ Да |
| Поиск по кодовой базе | ✅ Да |
| Короткие документы < 10K | ❌ Нет |

## Связанное

- [Туториал: InfiniRetri](../tutorials/06-infiniretri.md)
- [Концепция: RAG Pipeline](./rag.md)
