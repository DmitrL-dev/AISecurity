# üìö –£—Ä–æ–∫ 1.1: Attack Taxonomy

> **–í—Ä–µ–º—è: 45 –º–∏–Ω—É—Ç** | Expert Module 1

---

## Academic Classification

```
AI Attacks
‚îú‚îÄ‚îÄ Input-level
‚îÇ   ‚îú‚îÄ‚îÄ Direct Injection
‚îÇ   ‚îú‚îÄ‚îÄ Indirect Injection
‚îÇ   ‚îî‚îÄ‚îÄ Encoded Injection
‚îú‚îÄ‚îÄ Model-level
‚îÇ   ‚îú‚îÄ‚îÄ Adversarial Examples
‚îÇ   ‚îú‚îÄ‚îÄ Model Extraction
‚îÇ   ‚îî‚îÄ‚îÄ Model Poisoning
‚îú‚îÄ‚îÄ System-level
‚îÇ   ‚îú‚îÄ‚îÄ Tool Hijacking
‚îÇ   ‚îú‚îÄ‚îÄ Memory Attacks
‚îÇ   ‚îî‚îÄ‚îÄ Privilege Escalation
‚îî‚îÄ‚îÄ Output-level
    ‚îú‚îÄ‚îÄ Information Leakage
    ‚îú‚îÄ‚îÄ Harmful Generation
    ‚îî‚îÄ‚îÄ Hallucination Exploitation
```

---

## MITRE ATLAS Mapping

| Category | ATLAS Techniques |
|----------|------------------|
| Reconnaissance | AML.T0000 - AML.T0005 |
| Resource Dev | AML.T0010 - AML.T0015 |
| Initial Access | AML.T0020 - AML.T0030 |
| Execution | AML.T0040 - AML.T0050 |
| Persistence | AML.T0060 - AML.T0065 |
| Evasion | AML.T0070 - AML.T0080 |
| Exfiltration | AML.T0090 - AML.T0095 |

---

## Attack Surface Model

```python
class AttackSurface:
    """Model AI system attack surface."""
    
    vectors = {
        "input": ["user_prompt", "rag_documents", "tool_outputs"],
        "model": ["weights", "training_data", "inference"],
        "system": ["tools", "memory", "permissions"],
        "output": ["response", "actions", "side_effects"]
    }
    
    def enumerate(self, target: AISystem) -> List[AttackVector]:
        vectors = []
        for category, items in self.vectors.items():
            for item in items:
                if target.exposes(item):
                    vectors.append(AttackVector(category, item))
        return vectors
```

---

## –°–ª–µ–¥—É—é—â–∏–π —É—Ä–æ–∫

‚Üí [1.2: Detection Theory](./02-detection-theory.md)
